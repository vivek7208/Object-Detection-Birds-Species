{"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["# Amazon SageMaker Object Detection for Bird Species\n"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["## Setup\n","\n","Before preparing the data, there are some initial steps required for setup.\n"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"}},"source":["This notebook requires two additional Python packages:\n","* **OpenCV** is required for gathering image sizes and flipping of images horizontally.\n","* The **MXNet** runtime is required for using the im2rec tool."]},{"cell_type":"markdown","source":["This solution relies on a config file to run the provisioned AWS resources. Run the cell below to generate that file."],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import json\n","import os\n","import boto3"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["client = boto3.client(\"servicecatalog\")\n","cwd = os.getcwd().split(\"/\")\n","i = cwd.index(\"S3Downloads\")\n","pp_name = cwd[i + 1]\n","pp = client.describe_provisioned_product(Name=pp_name)\n","record_id = pp[\"ProvisionedProductDetail\"][\"LastSuccessfulProvisioningRecordId\"]\n","record = client.describe_record(Id=record_id)\n","\n","keys = [x[\"OutputKey\"] for x in record[\"RecordOutputs\"] if \"OutputKey\" and \"OutputValue\" in x]\n","values = [x[\"OutputValue\"] for x in record[\"RecordOutputs\"] if \"OutputKey\" and \"OutputValue\" in x]\n","stack_output = dict(zip(keys, values))\n","\n","with open(f\"/root/S3Downloads/{pp_name}/stack_outputs.json\", \"w\") as f:\n","    json.dump(stack_output, f)"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import sagemaker\n","\n","sess = sagemaker.Session()\n","\n","role = sagemaker.get_execution_role()\n","sagemaker_config = json.load(open(\"stack_outputs.json\"))\n","demo_endpoint_name = sagemaker_config[\"DemoEndpointName\"]\n","solution_bucket = sagemaker_config[\"SolutionS3Bucket\"]\n","region = sagemaker_config[\"AWSRegion\"]\n","library_version = sagemaker_config[\"LibraryVersion\"]\n","solution_name = sagemaker_config[\"SolutionName\"]"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}},{"cell_type":"markdown","source":["This is the demo notebook. We've already trained the object detection model and deploy it to a sagemaker endpoint for you. If you want to check the dataset and how we train the model, please proceed to the `object_detection_birds.ipynb` for more details."],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":["## Test the model"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":["Now that the trained model is deployed at an endpoint that is up-and-running, we can use this endpoint for inference.  The results of a call to the inference endpoint are in a format that is similar to the .lst format, with the addition of a confidence score for each detected object. The format of the output can be represented as `[class_index, confidence_score, xmin, ymin, xmax, ymax]`. Typically, we don't visualize low-confidence predictions.\n","\n","We have provided a script to easily visualize the detection outputs. You can visulize the high-confidence preditions with bounding box by filtering out low-confidence detections using the script below:"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n","    \"\"\"\n","    visualize detections in one image\n","    Parameters:\n","    ----------\n","    img : numpy.array\n","        image, in bgr format\n","    dets : numpy.array\n","        ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n","        each row is one object\n","    classes : tuple or list of str\n","        class names\n","    thresh : float\n","        score threshold\n","    \"\"\"\n","    import random\n","    import matplotlib.pyplot as plt\n","    import matplotlib.image as mpimg\n","\n","    img = mpimg.imread(img_file)\n","    plt.imshow(img)\n","    height = img.shape[0]\n","    width = img.shape[1]\n","    colors = dict()\n","    num_detections = 0\n","    for det in dets:\n","        (klass, score, x0, y0, x1, y1) = det\n","        if score < thresh:\n","            continue\n","        num_detections += 1\n","        cls_id = int(klass)\n","        if cls_id not in colors:\n","            colors[cls_id] = (random.random(), random.random(), random.random())\n","        xmin = int(x0 * width)\n","        ymin = int(y0 * height)\n","        xmax = int(x1 * width)\n","        ymax = int(y1 * height)\n","        rect = plt.Rectangle(\n","            (xmin, ymin),\n","            xmax - xmin,\n","            ymax - ymin,\n","            fill=False,\n","            edgecolor=colors[cls_id],\n","            linewidth=3.5,\n","        )\n","        plt.gca().add_patch(rect)\n","        class_name = str(cls_id)\n","        if classes and len(classes) > cls_id:\n","            class_name = classes[cls_id]\n","        print(\"{},{}\".format(class_name, score))\n","        plt.gca().text(\n","            xmin,\n","            ymin - 2,\n","            \"{:s} {:.3f}\".format(class_name, score),\n","            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n","            fontsize=12,\n","            color=\"white\",\n","        )\n","\n","    print(\"Number of detections: \" + str(num_detections))\n","    plt.show()"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}},{"cell_type":"markdown","source":["Now we use our endpoint to try to detect objects within an image. Since the image is a jpeg, we use the appropriate content_type to run the prediction. The endpoint returns a JSON object that we can simply load and peek into. We have packaged the prediction code into a function to make it easier to test other images.  Note that we are defaulting the confidence threshold to 30% in our example, as a couple of the birds in our sample images were not being detected as clearly.  Defining an appropriate threshold is entirely dependent on your use case."],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["import boto3\n","\n","runtime = boto3.client(service_name=\"runtime.sagemaker\")\n","\n","\n","OBJECT_CATEGORIES = ['017.Cardinal',\n","                     '036.Northern_Flicker',\n","                     '047.American_Goldfinch',\n","                     '068.Ruby_throated_Hummingbird',\n","                     '073.Blue_Jay']\n","\n","\n","def show_bird_prediction(filename, ep, thresh=0.40):\n","    b = \"\"\n","    with open(filename, \"rb\") as image:\n","        f = image.read()\n","        b = bytearray(f)\n","    endpoint_response = runtime.invoke_endpoint(EndpointName=ep, ContentType=\"image/jpeg\", Body=b)\n","    results = endpoint_response[\"Body\"].read()\n","    detections = json.loads(results)\n","    visualize_detection(filename, detections[\"prediction\"], OBJECT_CATEGORIES, thresh)"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}},{"cell_type":"markdown","source":["Here we download images that the algorithm has not yet seen."],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["from sagemaker.s3 import S3Downloader\n","\n","test_images_bucket = f\"s3://{solution_bucket}-{region}/{library_version}/{solution_name}\"\n","test_images_prefix = f\"artifacts/test_images\"\n","test_data = f\"{test_images_bucket}/{test_images_prefix}\"\n","print(\"test data: \")\n","S3Downloader.list(test_data)"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["!aws s3 cp --recursive --no-progress $test_data test_images"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}},{"cell_type":"markdown","source":["We have deployed the demo endpoint for you. You could directly use it and check the result."],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","execution_count":null,"outputs":[],"source":["def test_model():\n","    show_bird_prediction(\"test_images/hummingbird-1.jpg\", demo_endpoint_name)\n","    show_bird_prediction(\"test_images/blue-jay-1.jpg\", demo_endpoint_name)\n","    show_bird_prediction(\"test_images/multi-goldfinch-1.jpg\", demo_endpoint_name)\n","    show_bird_prediction(\"test_images/northern-flicker-1.jpg\", demo_endpoint_name)\n","    show_bird_prediction(\"test_images/northern-cardinal-1.jpg\", demo_endpoint_name)\n","\n","test_model()"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}},{"cell_type":"markdown","source":["## Clean up\n","Here we delete the SageMaker endpoint, as we will no longer be performing any inferences.  This is an important step, as your account is billed for the amount of time an endpoint is running, even when it is idle.\n","\n","Demo endpoints will be cleaned up after you delete the solution. You could also un-comment the below command to delete the endpoint."],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","execution_count":1,"outputs":[],"source":["# sagemaker.Session().delete_endpoint(demo_endpoint_name)"],"metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"}}}],"metadata":{"kernelspec":{"name":"python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/mxnet-1.9-cpu-py38-ubuntu20.04-sagemaker-v1.0"}},"nbformat":4,"nbformat_minor":2}